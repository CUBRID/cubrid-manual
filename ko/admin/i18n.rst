***********
다국어 지원
***********

다국어 지원(Globalization)은 다양한 언어와 지역에 적용될 수 있도록 하는 국제화(Internationalization)와 언어별 구성 요소를 추가하여 특정 지역의 언어나 문화에 맞추 현지화(Localization)를 포함한다. CUBRID는 현지화를 쉽게 하기 위해 유럽과 아시아를 포함한 여러 언어들의 콜레이션(collation)을 지원한다.

다국어 지원과 관련된 용어는 다음과 같다.

*   **문자셋(character set)** : 기호를 인코딩(어떤 기호에 특정 번호를 부여)한 집합

*   **콜레이션(collation)** : 문자셋에서 문자를 비교하기 위한, 데이터 정렬을 위한 규칙의 집합

*   **로캘(locale)** : 사용자의 언어 및 국가에 따라 숫자 형식, 캘린더(월의 이름, 요일의 이름), 날짜/시간 형식, 콜레이션, 통화 등을 정의하는 인자들의 집합. 로캘은 언어에 대한 지역화(localization)를 정의한다. 로캘의 문자셋은 월의 이름 및 다른 데이터가 어떻게 인코딩되는지를 나타낸다. 로캘은 최소한 하나의 언어 식별자와 영역 식별자로 구성되어 있으며 language[_territory][.codeset]으로 표현한다. (예를 들어 UTF-8 인코딩을 쓰는 오스트레일리아 영어는 en_AU.utf8로 표기한다.)

*   **유니코드 정규화** : 모양이 같은 여러 문자들이 있을 경우 기준에 따라 이를 하나로 통합하는 것. CUBRID는 입력 시에는 NFC(Normalization Form C) 형식(분해된 코드 코드포인트에서 결합된 코드포인트로 변환)을 사용하고, 출력 시에는 NFD(Normalization Form D) 형식(결합된 코드포인트에서 분해된 코드포인트로 변환)을 사용한다. 하지만, CUBRID는 예외적으로 규범적 등가(canonical equivalence) 규칙을 적용하지 않는다.

예를 들어, 일반적인 NFC 규칙에 따르면 규범적 등가 규칙을 적용하여 코드포인트 212A(캘빈 기호 ?)는 코드포인트 4B(ASCII 코드 대문자 K)로 변환된다. CUBRID는 규범적 등가 규칙에 의한 변환을 수행하지 않도록 하여 정규화 알고리즘을 더 간단하고 빠르게 하였고, 따라서 역변환도 수행하지 않는다.

*   **규범적 등가(canonical equivalence)** : 시각적으로 구별이 불가능하고 텍스트 비교상 정확히 동일한 의미를 가지는 문자. 한 예로 'A'에 옹스트롬(Angstrom) 기호가 있는 'Å'가 있는데, 'Å'(유니코드 U+212B)와 라틴어 'A'(유니코드 U+00C5)는 모양이 같고 코드포인트가 다르지만 분해된 결과는 'A'와 U+030A로 같으므로 규범적 등가이다.

*   **호환성 등가(compatibility equivalence)** : 동일한 문자나 문자 시퀀스의 대체 표현 문자. 예로는 숫자 '2'(유니코드 U+0032)와 위첨자 '²'(유니코드 U+00B2)가 있는데, '²' 는 숫자 '2'의 다른 형태이긴 하지만 시각적으로 구별되고 의미도 다르기 때문에 규범적 등가에 해당되지 않는다. '2²'를 NFC로 정규화하면 규범적 등가를 사용하기 때문에 '2²'가 유지되지만, NFKC 방식에서는 '²'가 호환성 등가인 '2'로 분해된 후 결합되어 '22'로 바뀔 수 있다. CUBRID의 유니코드 정규화에서는 호환성 등가 규칙도 적용하지 않는다.

유니코드 정규화에 대한 보다 자세한 내용은 `http://unicode.org/reports/tr15/ <http://unicode.org/reports/tr15/>`_ 를 참고한다.

유니코드 정규화 관련 시스템 파라미터에서 기본으로 설정되는 값은 unicode_input_normalization=no이고 unicode_output_normalization=no이다. 이 파라미터에 대한 보다 자세한 설명은 `구문/타입 관련 파라미터 <#pm_pm_db_classify_type_htm>`_ 를 참고한다.

**로캘 속성**

CUBRID 로캘은 다음과 같은 속성들로 정의된다.

*   **문자셋(코드셋)** : 여러 바이트를 하나의 문자로 해석하는 방법을 정의한다. 유니코드에서는 여러 개의 바이트가 하나의 코드포인트(codepoint)를 구성하는 것으로 해석된다.

*   **콜레이션(collation)** : LDML 파일의 로캘 데이터에 여러 콜레이션을 지정할 수 있는데, 이 중에 마지막으로 명시된 것이 기본 콜레이션으로 사용된다.

*   **알파벳(대소문자 규칙)** : 하나의 로캘 데이터는 테이블 이름, 칼럼 이름과 같은 식별자용과 사용자 데이터용으로 최대 두 종류의 알파벳을 가질 수 있다.

*   **캘린더** : 요일 이름, 월의 이름, 오전/오후(AM/PM) 표시

*   **숫자 표기** : 자릿수 구분 기호, 소수점 기호, 통화 형식

*   **텍스트 변환 데이터** : CSQL 콘솔 변환용 선택 사항. `CSQL을 위한 텍스트 변환 <#admin_admin_i18n_intro_htm_csql>`_ 을 참고한다.

*   **유니코드 정규화(unicode normalization) 데이터** : 모양이 같은 여러 문자들이 있을 경우 이를 기준에 따라 하나의 값으로 통합하는 정규화를 수행하여 변환된 데이터. 정규화 이후에는 로캘이 달라도 모양이 같은 문자는 같은 코드값을 가지며, 각 로캘은 이 정규화 기능을 활성화 또는 비활성화할 수 있다.

.. note::

	일반적으로 한 로캘은 다양한 문자셋을 지원하지만, CUBRID 로캘은 영어와 한국어에 한해서만 ISO와 UTF-8 문자셋을 둘 다 지원한다. 그 외의 LDML 파일을 이용한 모든 사용자 정의 로캘은 UTF-8 문자셋만 지원한다.

**CSQL을 위한 텍스트 변환**

CSQL 콘솔 인터페이스에서는 텍스트 변환 동작이 일어날 수 있다. 대부분의 로캘들은 콘솔에서 ASCII 문자를 쓰기 쉽게 하는 비표준 문자셋이 별도로 존재하므로 변환 작업이 필요하다. 예를 들어 로캘 tr_TR.utf8에 대한 LDML 파일에는 다음 라인이 포함되어 있다. ::

	<consoleconversion type="ISO88599" windows_codepage="28599" linux_charset="iso88599,ISO_8859-9,ISO8859-9,ISO-8859-9" />

사용자가 이와 같이 콘솔의 문자셋을 설정하면(예: Windows에서 chcp 28599, Linux에서 export LANG= tr_TR.iso88599), CUBRID는 모든 입력이 ISO-8859-9 문자셋으로 인코딩된다고 가정하여 모든 데이터를 UTF-8로 변환한다. 또한 결과를 출력할 때는 UTF-8을 ISO-8859-9로 변환하는 반대의 동작을 수행한다. Linux에서는 이러한 변환을 피하기 위해 UTF-8 콘솔(export LANG=tr_TR.utf8)을 직접 사용할 것을 권장한다.

XML 태그의 이 설정은 LDML 로캘 파일에서 반드시 요구되지는 않으며 선택 사항이다. 예를 들어, 로캘 km_KH.utf8은 Windows에서 관련 코드페이지가 없다.

**콜레이션 속성**

콜레이션(collation)은 문자열의 비교 및 정렬 규칙의 집합으로, CUBRID에서 콜레이션은 다음과 같은 속성(property)을 갖는다.

*   세기(strength): 기본 비교 항목들(문자들)이 어떻게 다른지 나타내는 측정 기준이다. 이것은 선택도(selectivity)에 영향을 미친다. LDML 파일에서 콜레이션의 세기는 네 가지 수준(level)으로 설정할 수 있다. 예를 들어, 대소문자 구분이 없는 콜레이션은 level = "secondary" (2)또는 "primary"(1)로 설정해야 한다.

*   확장(expansion)과 축약(contraction) 지원 여부

각각의 칼럼이 콜레이션을 가질 수 있기 때문에, :func:`LOWER`, :func:UPPER` 함수 등을 적용할 때 해당 콜레이션의 기본 언어에서 정의한 로캘의 대소문자 구분 규칙(casing rule)이 사용된다.

콜레이션 속성에 따라 일부 콜레이션에서 다음과 같은 특정 CUBRID 최적화가 동작하지 않을 수 있다.

*   **LIKE** 구문 재작성: 같은 가중치(weight)에 여러 개의 다른 문자를 매핑하는 콜레이션, 예를 들어 대소문자 구분이 없는 콜레이션에서는 **LIKE** 구문이 재작성되지 않는다.

*   커버링 인덱스 스캔: 같은 가중치에 여러 개의 다른 문자를 매핑하는 콜레이션에서는 커버링 인덱스 스캔이 동작하지 않는다(`인덱스 활용 > 커버링 인덱스 <#syntax_syntax_retreive_index_cov_7428>`_ 참고).

*   prefix 인덱스: 확장이 있는 콜레이션을 사용한 칼럼에서는 prefix 인덱스를 생성할 수 없다.

**로캘 저장 위치**

CUBRID는 로캘 설정을 위해 여러 디렉터리와 파일들을 사용한다.

*   **$CUBRID/conf/cubrid_locales.txt** 파일: 사용할 로캘 리스트를 포함하는 초기 설정 파일

*   **$CUBRID/conf/cubrid_locales.all.txt** 파일: **cubrid_locales.txt** 와 같은 구조를 갖는 초기 설정 파일의 템플릿. 사용자가 직접 정의하지 않아도 되는 CUBRID가 현재 지원하는 CUBRID 로캘 버전의 전체 리스트를 포함한다.

*   **$CUBRID/locales/data** 디렉터리: 로캘 데이터를 생성하는데 필요한 파일들을 포함한다.

*   **$CUBRID/locales/loclib** 디렉터리: 로캘 데이터를 포함하는 공유 라이브러리 생성을 위한 C 언어로 작성된 **locale_lib_common.h** 헤더 파일과 빌드를 위한 makefile을 포함한다.

*   **$CUBRID/locales/data/ducet.txt** 파일: 코드포인트, 축약과 확장 등과 같은 기본적인 범용 콜레이션 정보와 이들의 가중치 값을 표현하는 파일로, 이 정보들은 유니코드 콘소시엄에 의해 제정된 표준을 따른다. 자세한 사항은 `http://unicode.org/reports/tr10/#Default_Unicode_Collation_Element_Table <http://unicode.org/reports/tr10/#Default_Unicode_Collation_Element_Table>`_ 을 참고한다.

*   **$CUBRID/locales/data/unicodedata.txt** 파일: 대소문자 구별, 분해, 정규화 등 각각의 유니코드 코드 포인트를 포함하는 파일로, CUBRID는 대소문자 구분 규칙을 결정하기 위해 이 파일을 사용한다. 더 많은 정보는 `http://www.ksu.ru/eng/departments/ktk/test/perl/lib/unicode/UCDFF301.html <http://www.ksu.ru/eng/departments/ktk/test/perl/lib/unicode/UCDFF301.html>`_ 을 참고한다.

*   **$CUBRID/locales/data/ldml** 디렉터리: **cubrid_** <*locale_name*> **.xml** 형식의 이름을 지니는 XML 파일들을 포함한다. 각각의 XML 파일은 해당 언어에 대한 로캘 정보를 표현한다. (LDML: Locale Data Markup Language)

*   **$CUBRID/locales/data/codepages** 디렉터리: 한 바이트 코드 페이지들을 위한 코드 페이지 콘솔 변환용 파일들(8859-1.txt, 8859-15.txt, 8859-9.txt)과 멀티 바이트 코드 페이지를 위한 코드 페이지 콘솔 변환용 파일들(CP1258.txt, CP923.txt, CP936.txt, CP949.txt)을 포함한다.

*   **$CUBRID/bin/make_locale.sh** 파일 또는 **%CUBRID%\bin\make_locale.bat** 파일(Windows): 로캘 데이터를 표현하는 공유 라이브러리를 생성하기 위해 사용되는 스크립트 파일이다.

*   **$CUBRID/lib** 디렉터리: 로캘 데이터를 표현하는 공유 라이브러리 파일이 저장된다.

로캘(locale) 설정
=================

**1단계 : 로캘 선택**

CUBRID가 현재 지원하는 로캘은 en_US, de_DE, es_ES, fr_FR, it_IT, ja_JP, km_KH, ko_KR, tr_TR, vi_VN, zh_CN이며, 각 로캘 이름 및 언어, 사용 국가는 다음 표와 같다.

+-----------+----------------------+
| 로캘 이름 | 언어 - 사용 국가     |
+===========+======================+
| en_US     | 영어 - 미국          |
+-----------+----------------------+
| de_DE     | 독일어 - 독일        |
+-----------+----------------------+
| es_ES     | 스페인어 - 스페인    |
+-----------+----------------------+
| fr_FR     | 프랑스어 - 프랑스    |
+-----------+----------------------+
| it_IT     | 이태리어 - 이탈리아  |
+-----------+----------------------+
| ja_JP     | 일본어 - 일본        |
+-----------+----------------------+
| km_KH     | 크메르어 - 캄보디아  |
+-----------+----------------------+
| ko_KR     | 한국어 - 대한민국    |
+-----------+----------------------+
| tr_TR     | 터키어 - 터키        |
+-----------+----------------------+
| vi_VN     | 베트남어 - 베트남    |
+-----------+----------------------+
| zh_CN     | 중국어 - 중국        |
+-----------+----------------------+

이 목록은 **$CUBRID/conf/cubrid_locales.all.txt** 에 작성되어 있으며, 이 중에서 사용하려는 로캘을 **$CUBRID/conf/cubrid_locales.txt** 에 지정한다. 가능한 로캘을 모두 선택하거나 부분만 선택할 수 있다.

지원하는 로캘들을 위한 LDML 파일들은 **cubrid_** <*locale_name*> **.xml** 파일로 명명되며, **$CUBRID/locales/data/ldml** 폴더에 저장된다. 지원하려는 로캘에 해당하는 LDML 파일이 **$CUBRID/locales/data/ldml** 디렉터리에 존재해야 한다. **cubrid_locales.txt** 에 로캘이 지정되지 않거나 **cubrid_** <*locale_name*> **.xml** 파일이 존재하지 않으면 해당 로캘을 사용할 수 없다.

로캘 라이브러리들은 **$CUBRID/conf/cubrid_locales.txt** 설정 파일에 의해 생성되는데, 이 파일은 원하는 로캘들의 언어 코드들을 포함하고 있다. 사용자가 정의하는 모든 로캘들은 UTF-8 문자셋으로만 생성된다. 또한 이 파일을 통해서 각 로캘 LDML 파일에 대한 파일 경로와 라이브러리들을 선택적으로 설정할 수 있다. ::

	<lang_name> <LDML file>                    <lib file>
	ko_KR    /home/CUBRID/locales/data/ldml/cubrid_ko_KR.xml    /home/CUBRID/lib/libcubrid_ko_KR.so

기본적으로 LDML 파일은 **$CUBRID/locales/data/ldml** 디렉터리에, 로캘 라이브러리들은 **$CUBRID/lib** 디렉터리에 존재한다. 이와 같이 LDML 파일과 로캘 라이브러리가 기본 위치에 존재한다면 <*lang_name*>만 작성해도 된다. LDML을 위한 파일 이름 형식은 **cubrid_** <*lang_name*> **.ldml** 이다. 라이브러리에 대한 파일 이름 형식은 Linux에서는 **libcubrid_** <*lang_name*> **.so**, Windows에서는 **libcubrid_** <*lang_name*> **.dll** 이다.

**2단계: 로캘 컴파일하기**

1단계에서 설명한 요구사항들이 충족되었다면 로캘 데이터를 컴파일할 수 있다. 로캘 데이터를 컴파일하려면 **make_locale** 스크립트(파일의 확장자는 Linux에선 **.sh**, Windows에선 **.bat**)를 사용한다. 이 스크립트는 **$CUBRID/bin** 디렉터리에 위치하며, 이 경로가 **$PATH** 환경 변수에 포함되어야 한다. 여기서 **$CUBRID**, **$PATH** 는 Linux의 환경 변수이며, Windows에서는 **%CUBRID%**, **%PATH%** 이다.

사용법은 **make_locale.sh** **-h** (Windows는 **make_locale.bat /h**) 명령을 실행하면 출력되며, 사용 구문은 다음과 같다. ::

	make_locale.sh [OPTIONS] [LOCALE]
	 
	OPTIONS ::= [-t 32|64 ] [-m debug|release]
	LOCALE ::= [de_DE|es_ES|fr_FR|it_IT|ja_JP|km_KH|ko_KR|tr_TR|vi_VN|zh_CN]

*   *OPTIONS*

    *   **-t** : 32비트 혹은 64비트 중 하나를 선택한다(기본값: **32**).

    *   **-m** : **release** 혹은 **debug** 중 하나를 선택한다. 일반적인 사용을 위해서는 **release를** 선택한다(기본값 : **release**). **debug** 모드는 로캘 라이브러리를 직접 작성하려는 개발자를 위해 제공한다.

*   *LOCALE* : 빌드할 라이브러리의 로캘 이름. *LOCALE* 이 주어지지 않으면, 설정한 모든 로캘의 데이터를 포함하도록 빌드된다. 이 경우 **$CUBRID/lib** 디렉터리에 **libcubrid_all_locales.so** (Windows의 경우 **.dll**)라는 이름으로 라이브러리 파일이 저장된다.

여러 로캘에 대해서 사용자 정의 로캘 공유 라이브러리를 만들려면 다음 두 가지 방법 중 하나를 사용할 수 있다.

*   모든 로캘을 포함하는 하나의 라이브러리 생성: 다음과 같이 옵션을 지정하지 않고 실행한다. ::

	make_locale.sh                         # Build and pack all locales (32/release)

*   하나의 로캘만을 포함하는 라이브러리를 여러 개 반복하여 생성: 다음과 같이 하나의 언어를 지정한다. ::

	make_locale.sh -t 64 -m release ko_KR

이와 같은 두 가지 방법 중에서 첫 번째 방법을 사용하는 것을 권장한다. 이 방식으로 공유 라이브러리를 생성했을 경우에는 로캘들 간에 공유될 수 있는 데이터들이 중복되지 않기 때문에 메모리 사용량을 줄일 수 있다. 첫 번째 방식으로 지원하는 모든 로캘을 포함하도록 생성하면 약 15MB 정도 크기의 라이브러리가 생성되며, 두 번째 방식으로 생성할 경우에는 언어에 따라서 1MB에서 5MB 이상의 크기의 라이브러리가 생성된다. 또한 첫 번째 방식에서는 두 번째 방식을 사용했을 때에 서버 재시작 시점 등에 발생되는 런타임 오버헤드가 없기 때문에 런타임에도 유리하다.

**make_locale.sh(.bat) 스크립트 수행 절차**

**make_locale.sh** (**.bat**) 스크립트는 다음과 같은 작업을 수행한다.

*   **$CUBRID/locales/data/ducet.txt**, **$CUBRID/locales/data/unicodedata.txt**, **$CUBRID/locales/data/codepages/*.txt** 와 같이 이미 설치된 공통 파일과 해당 언어의 **.ldml** 파일을 읽는다.

*   원본(raw) 데이터를 처리한 후 **$CUBRID/locales/loclib/locale.c** 임시 파일에 로캘 데이터를 포함하는 C 상수 값과 배열을 작성한다.

*   **.so** (**.dll**) 파일을 빌드하기 위해 임시 파일인 **locale.c** 파일이 플랫폼 컴파일러에 전달된다. 이 단계는 장비가 C/C++ 컴파일러 및 링커를 가지고 있다고 가정한다. 현재 Windows용으로는 MS Visual Studio가, Linux용으로는 gcc 컴파일러가 지원된다.

*   임시 파일이 삭제된다.

**제약 사항 및 규칙**

*   일단 로캘 라이브러리가 생성된 후에는 **$CUBRID/conf/cubrid_locales.txt** 파일을 변경하면 안 된다. 이 파일에서 명시된 언어들의 순서를 포함하여 어떤 내용도 변경해서는 안 된다. 로캘이 새로 생성될 때마다 기존의 식별 번호가 증가하면서 새로운 식별 번호로 등록되며, 이러한 식별 번호는 로캘이 로딩될 때마다 항상 같은 값으로 유지되고 있는지 검사하게 된다.

*   **$CUBRID/locales/data/*.txt** 파일들은 변경되어서는 안 된다.

CUBRID에 내장된 로캘에 대해서는 사용자 로캘 라이브러리를 컴파일하지 않고 사용할 수 있으므로 2단계를 생략할 수 있으나, 내장된 로캘과 라이브러리 로캘에는 다음과 같은 차이가 있다.

*   내장된(built-in) 로캘(과 콜레이션)은 유니코드 데이터를 인식하지 못한다. 예를 들어, 내장된 로캘은 A, a 간 대소문자 변환이 불가능하다. 반면 LDML 로캘(컴파일된 로캘)은 유니코드 코드포인트에 대한 데이터를 65535개까지 지원한다.

*   내장된 콜레이션은 ASCII 범위만 다루거나, utf8_tr_cs의 경우 ASCII와 터키어(turkish) 알파벳 글자만 다룬다. 따라서 내장된 UTF-8 로캘은 유니코드와 호환되지 않는 반면, LDML 로캘(컴파일된 로캘)은 유니코드와 호환된다.

**CUBRID_LANG** 환경 변수로 설정할 수 있는 내장 로캘은 다음과 같다.

*   en_US.iso88591
*   en_US.utf8
*   ko_KR.utf8
*   ko_KR.euckr
*   ko_KR.iso88591 : 월, 요일 표시 방법은 로마자 표기를 따른다(romanized).
*   tr_TR.utf8
*   tr_TR.iso88591 : 월, 요일 표시 방법은 로마자 표기를 따른다(romanized).

만약 **CUBRID_LANG** 설정 시 문자셋(charset)이 명시되지 않으면 위 순서에서 앞에 있는 로캘의 문자셋으로 결정된다. 예를 들어, **CUBRID_LANG** 가 ko_KR로 설정되면 위의 목록에서 ko_KR 중 가장 먼저 나타나는 로캘인 ko_KR.utf8을 지정한 것과 같다. 위의 내장된 로캘을 제외한 나머지 언어의 로캘은 뒤에 반드시 **.utf8** 을 붙여야 한다. 예를 들어, 독일어의 경우 **CUBRID_LANG** 을 de_DE.utf8로 지정한다.

ko_KR.iso88591과 tr_TR.iso88591에서 월과 요일을 나타낼 때에는 로마자 표기를 따른다. 예를 들어, 한국어 "일요일"(영어로 Sunday)의 로마자 표기는 "Iryoil"이다. 이것은 ISO-8859-1 문자만 제공하기 위해서 요구되는 사항이다.

**3단계: 특정 로캘을 사용하기 위해 CUBRID 설정하기**

여러 로캘을 정의할 수 있지만, **CUBRID_LANG** 환경 변수를 통해 오직 하나의 로캘을 기본 로캘로 지정할 수 있다. 언어에 따른 기본 캘린더(요일, 월, 오전/오후 표기 형식) 설정은 **intl_date_lang** 시스템 파라미터로 설정할 수 있다.

*   **CUBRID_LANG** 환경 변수의 값은 <*locale_name*>[**.utf8** | **.iso88591**]과 같이 설정한다. (예: tr_TR.utf8, en_US.iso88591, ko_KR.utf8)

*   **intl_date_lang** 시스템 파라미터의 값은 <*locale_name*>과 같이 설정한다. <*locale_name*>으로 사용할 수 있는 값은 `1단계: 로캘 선택 <#admin_admin_i18n_locale_htm_01>`_ 을 참고한다.

**CUBRID_LANG** 환경 변수는 제품 설치 초기에 en_US(문자셋은 ISO-8859-1)로 설정되어 있다.

**4단계: 선택한 로캘 설정으로 데이터베이스 생성하기**

**CUBRID_LANG** 환경 변수를 설정하면 새로운 데이터베이스를 생성할 수 있다. **cubrid createdb** <*db_name*>을 실행하면, 해당 언어와 문자셋을 사용하는 데이터베이스가 생성된다. 일단 데이터베이스가 생성되면 이 설정은 바꿀 수 없다. 문자셋과 로캘 이름은 *db_root* 라는 시스템 카탈로그 테이블에 저장되며, 생성 시점의 설정과 다른 설정을 사용하여 데이터베이스를 구동할 수 없다.

**5단계(선택 사항): 로캘 파일의 수동 검증**

로캘 라이브러리의 내용들을 **dumplocale** 유틸리티를 이용해서 사람이 읽을 수 있는 형태로 출력할 수 있다. 사용법은 **cubrid dumplocale -h** 로 출력할 수 있으며, 사용 구문은 다음과 같다. ::

	cubrid dumplocale [OPTION] [language-string]
	 
	OPTION ::= [-i|--input-file <shared_lib>] [-d|--calendar] [-n|--numeric] [{-a |--alphabet=}{l|lower|u|upper|both}] [-c|--codepoint-order] [-w|--weight-order] [{-s|--start-value} <starting_codepoint>] [{-e|--end-value} <ending_codepoint>] [-k] [-z]
	 
	language-string ::= de_DE|es_ES|fr_FR|it_IT|ja_JP|km_KH|ko_KR|tr_TR|vi_VN|zh_CN

*   *OPTION*

    *   **-i**, **--input-file** : 이전에 생성된 로캘 공유 라이브러리 파일(<*shared_lib*>) 이름. 경로를 포함한다.

    *   **-d**, **--calendar** : 캘린더와 날짜/시간 정보를 덤프. 기본값: 사용 안 함

    *   **-n**, **--numeric** : 숫자 정보를 덤프. 기본값: 사용 안 함

    *   **-a**, **--alphabet=l** | **lower** | **u** | **upper** | **both** : 알파벳과 대소문자 정보를 덤프. 기본값: 사용 안 함

    *   **--identifier-alphabet=l** | **lower** | **u** | **upper** | **both** : 식별자에 대한 알파벳과 대소문자 구분 정보를 덤프. 기본값: 사용 안 함

    *   **-c**, **--codepoint-order** : 코드포인트 값을 기반으로 정렬한 콜레이션 정보를 덤프. 기본값: 사용 안 함 (출력되는 정보: cp, char, weight, next-cp, char and weight)

    *   **-w**, **--weight-order** : 가중치 값을 기반으로 정렬한 콜레이션 정보를 덤프. 기본값: 사용 안 함 (출력되는 정보: weight, cp, char)

    *   **-s**, **--start-value** : 덤프 범위 지정. **-a** , **--identifier-alphabet** , **-c**, **-w** 옵션들에 대한 시작 코드포인트. 기본값: 0

    *   **-e**, **--end-value** : 덤프 범위 지정. **-a**, **--identifier-alphabet**, **-c**, **-w** 옵션들에 대한 끝 코드포인트. 기본값: 로캘 공유 라이브러리에서 읽은 최대값.

    *   **-k, --console-conversion** : 콘솔 변환 데이터를 덤프. 기본값: 사용 안 함

    *   **-z**, **--normalization** : 정규화 데이터를 덤프. 기본값: 사용 안 함

*   *language-string* : 로캘 공유 라이브러리를 덤프할 로캘 언어를 지정한다. *language-string* 이 입력되지 않으면, **cubrid_locales.txt** 파일에 명시된 모든 언어가 주어진다.

다음은 캘린더 정보, 숫자 표기 정보, 알파벳 및 대소문자 정보, 식별자에 대한 알파벳 및 대소문자 정보, 코드포인트 순서에 기반한 콜레이션의 정렬, 가중치에 기반한 콜레이션의 정렬, 데이터를 정규화하여 ko_KR 로캘의 내용을 dump.txt라는 파일에 덤프하는 예이다. ::

	cubrid dumplocale -d -n -a both -c -w -z ko_KR > ko_KR_dump.txt

여러 개의 옵션을 설정하면 출력되는 내용이 매우 많을 수 있으므로, 파일로 리다이렉션하여 저장할 것을 권장한다.

**6단계: CUBRID 관련 프로세스 시작**

모든 CUBRID 관련 프로세스는 같은 환경 설정을 통해 구동되어야 한다. CUBRID 서버, 브로커, CAS, CSQL 등은 **CUBRID_LANG** 환경 변수의 설정값이 모두 같아야 하며, 같은 버전의 로캘 바이너리 파일을 사용해야 한다. CUBRID HA, CUBRID SHARD 구성 시에도 마찬가지이다. 예를 들어, CUBRID HA 구성에서 마스터 서버, 슬레이브 서버와 레플리카 서버 등은 환경 설정이 모두 같아야 한다.

서버 프로세스와 CAS 프로세스에 의해 사용되는 로캘의 호환성 여부를 시스템이 자동으로 검사하지 않기 때문에, 두 프로세스 간에 LDML 파일들이 똑같다는 것을 보장해야 한다.

로캘 라이브러리 로딩은 CUBRID 구동의 첫 단계로서, 구동 시에 데이터베이스 구조를 초기화하기 위해 로캘 정보를 요구하는 서버, CAS, CSQL, createdb, copydb, unloaddb, loaddb 프로세스 등은 구동 시점에 로캘 라이브러리를 로딩한다.

로캘 라이브러리 로딩 절차는 다음과 같다.

*   라이브러리 경로가 제공되지 않으면 **$CUBRID/lib/libcubrid_** <*lang_name*> **.so** 의 로딩을 시도한다. 이 파일이 발견되지 않으면 하나의 파일 (**$CUBRID/lib/libcubrid_all_locales.so**) 에서 모든 로캘이 발견된다고 간주한다.

*   로캘 라이브러리가 발견되지 않거나 라이브러리를 로딩하는 동안 오류가 발생하면 CUBRID 프로세스 구동이 종료된다.

**참고 사항**

**월, 요일, 오전/오후 표기 및 숫자 형식 설정**

날짜/시간을 입출력하는 함수에서 각 로캘 이름에 따라 입출력하는 월, 요일, 오전/오후 표기 방법을 **intl_date_lang** 시스템 파라미터로 설정할 수 있다. 또한 문자열을 숫자로 혹은 숫자를 문자열로 변환하는 함수에서 각 로캘에 따라 입출력하는 숫자의 문자열 형식은 **intl_number_lang** 시스템 파라미터로 설정할 수 있다.

**ISO-8859-1 문자셋에서 한국어와 터키어의 월, 요일**

문자셋이 UTF-8인 한국어나 터키어 또는 문자셋이 EUC-KR인 한국어에서 월, 요일, 오전/오후 표시는 각 국가에 맞게 인코딩된다. 그러나, ISO-8859-1 문자셋에서 한국어와 터키어의 월, 요일, 오전/오후 표시를 원래의 인코딩으로 사용하면 복잡한 표현식이 사용되는 경우 서버 프로세스에서 예기치 않은 행동이 발생할 수 있기 때문에, 로마자 표기(romanized)로 출력한다. CUBRID의 기본 문자셋은 ISO-8859-1이며, 한국어와 터키어의 경우 이 문자셋을 사용할 수 있다. 한국어와 터키어에서 각 요일, 월, 오전/오후는 로마자로 다음과 같이 출력한다.

**요일**

+---------------------+----------------------------+-----------------------+
| 긴 형식 / 짧은 형식 | 한국어 긴 형식 / 짧은 형식 | 터키어 긴 / 짧은 형식 |
+=====================+============================+=======================+
| Sunday / Sun        | Iryoil / Il                | Pazar / Pz            |
+---------------------+----------------------------+-----------------------+
| Monday / Mon        | Woryoil / Wol              | Pazartesi / Pt        |
+---------------------+----------------------------+-----------------------+
| Tuesday / Tue       | Hwayoil / Hwa              | Sali / Sa             |
+---------------------+----------------------------+-----------------------+
| Wednesday / Wed     | Suyoil / Su                | Carsamba / Ca         |
+---------------------+----------------------------+-----------------------+
| Thursday / Thu      | Mogyoil / Mok              | Persembe / Pe         |
+---------------------+----------------------------+-----------------------+
| Friday / Fri        | Geumyoil / Geum            | Cuma / Cu             |
+---------------------+----------------------------+-----------------------+
| Saturday / Sat      | Toyoil / To                | Cumartesi / Ct        |
+---------------------+----------------------------+-----------------------+

**월**

+---------------------+---------+-----------------------+
| 긴 형식 / 짧은 형식 | 한국어  | 터키어 긴 / 짧은 형식 |
+=====================+=========+=======================+
| January / Jan       | 1wol    | Ocak / Ock            |
+---------------------+---------+-----------------------+
| February / Feb      | 2wol    | Subat / Sbt           |
+---------------------+---------+-----------------------+
| March / Mar         | 3wol    | Mart / Mrt            |
+---------------------+---------+-----------------------+
| April / Apr         | 4wol    | Nisan / Nsn           |
+---------------------+---------+-----------------------+
| May / May           | 5wol    | Mayis / Mys           |
+---------------------+---------+-----------------------+
| June / Jun          | 6wol    | Haziran / Hzr         |
+---------------------+---------+-----------------------+
| July / Jul          | 7wol    | Temmuz / Tmz          |
+---------------------+---------+-----------------------+
| August / Aug        | 8wol    | Agustos / Ags         |
+---------------------+---------+-----------------------+
| September / Sep     | 9wol    | Eylul / Eyl           |
+---------------------+---------+-----------------------+
| October / Oct       | 10wol   | Ekim / Ekm            |
+---------------------+---------+-----------------------+
| November / Nov      | 11wol   | Kasim / Ksm           |
+---------------------+---------+-----------------------+
| December / Dec      | 12wol   | Aralik / Arl          |
+---------------------+---------+-----------------------+

**오전/오후**

+-----------+---------+---------+
| 오전/오후 | 한국어  | 터키어  |
+===========+=========+=========+
| AM        | ojeon   | AM      |
+-----------+---------+---------+
| PM        | ohu     | PM      |
+-----------+---------+---------+

콜레이션 설정
=============

콜레이션(collation)이란 문자열 비교 및 정렬 규칙의 집합이다. 콜레이션의 전형적인 유형은 알파벳 순서의 정렬(alphabetization)이다.

CUBRID는 유럽과 아시아 언어를 포함한 여러 가지 언어들의 콜레이션을 지원한다. 이러한 언어들은 다른 알파벳들을 사용할 뿐만 아니라, 특정 언어들은 일부 문자셋에 대해 확장(expansion) 또는 축약(contraction) 정의를 필요로 한다. 이러한 사항들의 대부분은 The Unicode Consortium에 의해 유니코드 표준(2012년 현재 버전 6.1.0)으로 제정되어 있으며, 대부분의 언어가 요구하는 모든 문자 정보는 DUCET 파일(`http://www.unicode.org/Public/UCA/latest/allkeys.txt <http://www.unicode.org/Public/UCA/latest/allkeys.txt>`_ )에 저장되어 있다.

이러한 DUCET에 표현된 대부분의 코드포인트는 0~FFFF 내의 범위에 포함되지만, 이 범위를 넘는 코드포인트도 존재한다. 하지만 CUBRID는 0~FFFF 내의 코드포인트만 사용하고, 나머지들은 무시한다(하위 부분만 사용하도록 설정할 수도 있다).

DUCET에 있는 각각의 코드포인트는 하나 또는 그 이상의 콜레이션 원소(element)를 가지고 있다. 하나의 콜레이션 원소는 네 개 숫자 값의 집합으로, 문자 비교의 네 가지 수준(level)을 가중치(weight)로 표현한다. 각각의 가중치 값은 0~FFFF의 범위를 가진다.

DUCET에서 한 문자는 하나의 라인으로 다음과 같이 표현된다. ::

	< codepoint_or_multiple_codepoints >  ; [.W1.W2.W3.W4][....].... # < readable text explanation of the symbol/character >

한국어 문자 기역은 다음과 같이 표현된다. ::

	1100  ; [.313B.0020.0002.1100] # HANGUL CHOSEONG KIYEOK

위의 예에서 1100은 코드포인트, [.313B.0020.0002.1100]은 하나의 콜레이션 원소이며, 313B는 Level 1, 0020은 Level 2, 0002는 Level 3, 1100은 Level 4의 가중치이다.

언어의 기능적 속성으로 정의되는 확장 지원은 하나의 결합 문자를 그것을 만드는 한 쌍의 문자들로 해석하도록 지원한다는 것을 의미한다. 예를 들어 한 문자 ''æ'' 을 두 개의 문자 ''ae''와 같은 문자로 해석한다. DUCET에서 확장은 하나의 코드포인트나 축약에 대해 하나 이상의 콜레이션 원소들로 표현된다. 확장이 있는 콜레이션을 다루는 것은 두 개의 문자열을 비교할 때 콜레이션의 세기/수준까지 여러 번 비교하는 비용을 감수해야 하기 때문에, CUBRID는 기본적으로는 확장을 지원하지 않도록 설정되어 있다.

문자셋과 문자열의 콜레이션
--------------------------

칼럼의 콜레이션과 문자셋은 문자열 데이터 타입(**VARCHAR**, **CHAR**)에 적용된다. 기본적으로 모든 문자열 데이터 타입은 데이터베이스의 기본 콜레이션과 문자셋을 따르는데, 이를 적용하지 않고 변경하여 지정할 수 있는 방법을 제공한다.

**문자셋**

문자셋은 문자열 리터럴이나 따옴표 없는 식별자(identifier)로 명시될 수 있으며, 지원하는 문자셋은 다음과 같다.

*   ISO-8859-1(*)
*   UTF-8(문자당 최대 4바이트 길이, 즉 0~0x10FFFF 범위 내의 코드포인트를 지원)
*   EUC-KR(이 문자셋은 하위 호환을 위해서 존재할 뿐 사용을 권장하지 않는다.)

.. note::

	CUBRID 9.0 미만 버전까지는 ISO-8859-1 문자셋이 설정되면 EUC-KR 문자들을 사용할 수 있도록 지원했지만, 이후 버전부터는 이를 지원하지 않는다. EUC-KR 문자들은 오직 EUC-KR 문자셋에서만 사용될 수 있다.

**문자열 검사**

기본적으로 모든 입력 데이터는 서버에서 **CUBRID_LANG** 환경 변수로 설정한 문자로 간주한다. 하지만 **SET NAMES** 문이나 **CHARSET** 소개자(또는 **COLLATE** 문자열 수정자)가 **CUBRID_LANG** 환경 변수 설정보다 우선한다(`다국어 지원 > 콜레이션 설정 > 문자셋과 문자열의 콜레이션 <#admin_admin_i18n_collation_strin_3003>`_ 참고).

서버 문자셋이 UTF-8인데 UTF-8 바이트 순서(byte sequence)에 맞지 않는 데이터와 같이 무효한 데이터에 대해 문자열을 검사하지 않으면 정의되지 않은 동작을 보이거나 심지어 서버가 비정상 종료(crash)될 수 있다. 기본적으로는 문자열을 검사하지 않도록 설정되어 있다. 문자열을 검사하려면 **intl_check_input_string** 시스템 파라미터의 값을 yes로 설정한다(기본값: no). 하지만 유효한 데이터만 입력된다고 보장할 수 있다면 문자열 검사는 하지 않는 것이 성능상 더 유리하다. **intl_check_input_string** 시스템 파라미터의 값이 yes인 경우, UTF-8과 EUC-KR에 대해서만 유효한 데이터 인코딩인지 검사한다. ISO-8859-1은 한 바이트 인코딩이므로 모든 바이트 값이 유효하기 때문에 검사하지 않는다.

**문자셋 변환**

콜레이션/문자셋 수정자(**COLLATE** / **CHARSET**) 또는 콜레이션 추론 과정에 의해서 문자셋 변환이 일어날 수 있는데, 이러한 문자셋 변환은 비가역적(irreversible)이다. 예를 들어 ISO 8859-1 문자셋을 UTF-8 문자셋으로 변환하는 경우, 발음 구별 기호(accent mark)가 있는 문자(e) 같은 일부 문자에서 손실이 발생할 수 있다. ISO-8859-1 문자셋에서 80~A0 바이트 범위의 문자는 UTF-8 문자셋에서 이에 해당하는 문자가 없으므로 '?'로 대체된다.

UTF-8 또는 EUC-KR 문자셋에서 ISO 문자셋으로의 변환은 간단한 데이터 스트림 재해석 과정으로, 대부분의 유니코드 문자는 ISO 문자에 대응되지 못한다. 00~7F 바이트 범위는 ISO와 UTF-8 문자셋에서 같은 문자로 인코딩되기 때문에 ASCII 문자는 문자셋 변환에 영향을 받지 않는다.

한 문자에서 다른 문자로 변환되는 규칙은 다음과 같다.

+------------------------+------------------------+-------------------------+------------+
| Source \ Destination   | ISO-8859-1             | UTF-8                   | EUC-KR     |
+========================+========================+=========================+============+
| **ISO-8859-1**         | 변환 없음              | 바이트 변환.            | 허용 안 함 |
|                        |                        | 바이트 크기가 증가되며  |            |
|                        |                        | 문자 길이는 같음.       |            |
+------------------------+------------------------+-------------------------+------------+
| **UTF-8**              | 바이트 재해석.         | 변환 없음               | 허용 안 함 |
|                        | 바이트 크기는 같으며   |                         |            |
|                        | 문자 길이는 증가.      |                         |            |
+------------------------+------------------------+-------------------------+------------+
| **EUC-KR**             | 바이트 재해석.         | 허용 안 함              | 변환 없음  |
|                        | 바이트 크기는 같으며   |                         |            |
|                        | 문자 길이는 증가.      |                         |            |
+------------------------+------------------------+-------------------------+------------+

**콜레이션**

콜레이션은 문자열 리터럴이나 따옴표 없는 식별자로 명시될 수 있다.

다음은 내장된 콜레이션에 대한 **db_collation** 시스템 카탈로그 뷰의 질의 결과이다. ::

	coll_id  coll_name        charset_name    is_builtin  has_expansions  contractions  uca_strength
	================================================================================================
	0        'iso88591_bin'   'ISO8859-1'    'YES'        'NO'            0             'NOT APPLICABLE'
	1        'utf8_bin'       'UTF-8'        'YES'        'NO'            0             'NOT APPLICABLE'
	2        'iso88591_en_cs' 'ISO8859-1'    'YES'        'NO'            0             'NOT APPLICABLE'
	3        'iso88591_en_ci' 'ISO8859-1'    'YES'        'NO'            0             'NOT APPLICABLE'
	4        'utf8_en_cs'     'UTF-8'        'YES'        'NO'            0             'NOT APPLICABLE'
	5        'utf8_en_ci'     'UTF-8'        'YES'        'NO'            0             'NOT APPLICABLE'
	6        'utf8_tr_cs'     'UTF-8'        'YES'        'NO'            0             'NOT APPLICABLE'
	7        'utf8_ko_cs'     'UTF-8'        'YES'        'NO'            0             'NOT APPLICABLE'
	8        'euckr_bin'      'KSC-EUC'      'YES'        'NO'            0             'NOT APPLICABLE'

내장된(built-in) 콜레이션은 사용자 로캘 라이브러리의 추가 없이 사용 가능하며, 각 콜레이션은 관련 문자셋을 가지고 있기 때문에 문자셋과 콜레이션이 호환되지 않도록 지정하는 것은 허용되지 않는다.

**COLLATE** 수정자가 **CHARSET** 없이 명시되면, 콜레이션의 기본 문자셋이 설정된다. **CHARSET** 수정자가 **COLLATE** 없이 명시되면, 기본 콜레이션이 설정된다.

문자셋들에 대한 기본 콜레이션은 바이너리 콜레이션으로, 문자셋 및 이에 대응되는 바이너리 콜레이션은 다음과 같다.

*   ISO-8859-1: iso88591_bin
*   UTF-8: utf8_bin
*   EUC-KR: euckr_bin

서로 다른 콜레이션(과 문자셋)을 가진 표현식 인자(피연산자)를 가질 때 어떤 콜레이션을 사용할지 결정하는 방법에 대해서는 아래의 `칼럼의 콜레이션이 서로 다를 때 결정 방식 <#admin_admin_i18n_collation_colum_573>`_ 을 참고한다.

**구문**

기본 데이터베이스 콜레이션과 문자셋을 따르지 않고 콜레이션과 문자셋을 변경하여 지정할 수 있는 두 개의 문자열 타입에 대한 수정자를 제공한다.

*   **CHARACTER_SET** (또는 **CHARSET**)은 칼럼의 문자셋을 바꾼다.
*   **COLLATE** (또는 **COLLATION**)은 칼럼의 콜레이션을 바꾼다.

::

	<data_type> ::=
	<column_type> [<charset_modifier_clause>] [<collation_modifier_clause>]
	 
	<charset_modifier_clause> ::= {CHARACTER_SET | CHARSET} {<char_string_literal> | <identifier> }
	 
	<collation_modifier_clause> ::= {COLLATE | COLLATION} {<char_string_literal> | <identifier> }

**예제**

다음은 **STRING** 타입(**VARCHAR** 타입의 최대값) 칼럼의 문자셋을 UTF-8로 설정하는 예이다.

.. code-block:: sql

	CREATE TABLE t1 (s1 STRING CHARSET utf8);

다음은 칼럼 s1의 이름을 c1으로 바꾸고, 해당 타입을 콜레이션이 utf8_en_cs인 CHAR(10) 으로 바꾸는 예이다. 문자셋은 해당 콜레이션에 대한 기본 문자셋인 UTF-8으로 지정된다.

.. code-block:: sql

	ALTER TABLE t1 CHANGE s1 c1 CHAR(10) COLLATE utf8_en_cs;

다음은 c1 칼럼의 값을 콜레이션 iso88591_en_ci인 VARCHAR(5) 타입으로 바꿔 출력한다. 정렬 연산 또한 첫번째로 선택된 칼럼의 타입에 대한 콜레이션 iso88591_en_ci을 사용하여 수행된다.

.. code-block:: sql

	SELECT CAST (c1 as VARCHAR(5) COLLATE 'iso88591_en_ci') FROM t1 ORDER BY 1;

다음은 위와 유사한 질의(같은 정렬)이지만, 출력되는 칼럼 결과가 원래의 값이다.

.. code-block:: sql

	SELECT c1 FROM t1 ORDER BY CAST (c1 as VARCHAR(5) COLLATE iso88591_en_ci);

**칼럼의 콜레이션이 서로 다를 때 결정 방식**

CUBRID는 칼럼(표현식)들이 서로 다른 콜레이션과 문자셋을 가지고 있을 때 어떤 콜레이션과 문자셋으로 감지할 것인지를 결정한다.

.. code-block:: sql

	CREATE TABLE t (s1 STRING COLLATE utf8_en_cs, s2 STRING COLLATE utf8_tr_cs);

	-- insert values into both columns
	SELECT s1, s2 FROM t WHERE s1 > s2;

위의 예에서 칼럼 s1과 s2 는 다른 콜레이션을 가지고 있고, s1과 s2 를 비교한다는 것은 테이블 t에 있는 레코드끼리 어떤 칼럼의 값이 "더 큰지" 결정할 수 있는 문자열을 비교한다는 것을 의미한다. 콜레이션 utf8_en_cs와 utf8_tr_cs는 서로 비교할 수 없으므로 에러를 출력할 것이다.

표현식의 타입 결정 방법의 원칙이 콜레이션 결정 방법에도 마찬가지로 적용된다.

*   표현식의 모든 인자들을 고려하여 공통 콜레이션과 문자셋을 결정한다.
*   1에서 결정된 공통 콜레이션과 문자셋과 다른 인자들을 변환한다.
*   콜레이션을 변경하기 위해서 :func:`CAST` 가 사용될 수 있다.

비교 표현식의 결과 콜레이션을 결정하기 위해 "콜레이션 변환도(collation coercibility)"를 사용한다. 이는 자신의 콜레이션이 얼마나 쉽게 상대 인자의 콜레이션으로 변환되기 쉬운가를 표현한 것으로, 표현식의 두 피연산자를 비교할 때 콜레이션 변환도가 크다는 것은 상대 인자의 콜레이션으로 쉽게 변환된다는 것을 의미한다. 즉, 높은 변환도를 지닌 인자는 더 낮은 변환도를 지닌 인자의 콜레이션으로 변환될 수 있다.

표현식의 인자들이 서로 다른 콜레이션을 가지면, 이들에 대한 공통 콜레이션은 각 인자들의 콜레이션과 변환도에 기반하여 결정된다.

#.   높은 변환도를 가진 인자는 더 낮은 변환도를 가진 인자의 콜레이션으로 변환된다.
#.   인자들의 콜레이션이 서로 다르고 변환도는 같은 경우에는 표현식의 콜레이션을 결정할 수 없고 에러가 리턴된다.

표현식의 인자들의 변환도는 다음의 표와 같다.

+----------------------------+------------------------------------------------------------------------------------------+
| 콜레이션 변환도            | 표현식의 인자(피연산자)                                                                  |
+============================+==========================================================================================+
| 5                          | 상수, 호스트 변수, 기본 시스템 콜레이션을 가진 인자(iso88591_bin, utf8_bin)              |
| 변환 가능(문자열)          | (바이너리 콜레이션은 인자 타입의 변환도를 오버라이드한다. 일반적인 칼럼 인자들은 변환이  |
|                            | 안 되지만, 바이너리 콜레이션이 있는 칼럼의 변환도는 5로 완전히 변환 가능하다.)           |
+----------------------------+------------------------------------------------------------------------------------------+
| 4                          | 특수 함수들(:func:`USER`, :func:`DATABASE`,:func:`SCHEMA`,:func:`VERSION`)               |
| 변환 가능(시스템 상수)     |                                                                                          |
+----------------------------+------------------------------------------------------------------------------------------+
| 3                          | **SELECT**                                                                               |
| 변환 가능(표현식)          | 값, 서브 표현식(sub-expression)                                                          |
+----------------------------+------------------------------------------------------------------------------------------+
| 2                          | 현재 사용 안 함                                                                          |
| 변환 가능 예약됨           |                                                                                          |
+----------------------------+------------------------------------------------------------------------------------------+
| 1                          | 칼럼                                                                                     |
| 변환 가능(내포된 콜레이션) |                                                                                          |
+----------------------------+------------------------------------------------------------------------------------------+
| 0                          | 현재 사용 안 함                                                                          |
| 변환 불가(명시적 콜레이션) |                                                                                          |
+----------------------------+------------------------------------------------------------------------------------------+

콜레이션이 서로 다른 두 개의 인자가 하나의 콜레이션으로 변환되는 경우를 살펴보면 다음과 같다.

**원하는 콜레이션을 지정하여 변환**

앞의 예제에서 실행에 실패한 **SELECT** 문은 다음 질의문처럼 한 칼럼에 **CAST** 함수로 콜레이션을 지정하여 두 피연산자를 같은 콜레이션을 갖도록 하면 성공적으로 수행된다.

.. code-block:: sql

	SELECT s1, s2 FROM t WHERE s1 > CAST (s2 AS STRING COLLATE utf8_en_cs);

또는 s2를 바이너리 콜레이션으로 **CAST** 하면 s1의 콜레이션으로 변환도 5로 "완전히 변환 가능"하다.

.. code-block:: sql

	SELECT s1, s2 FROM t WHERE s1 > CAST (s2 AS STRING COLLATE utf8_bin);

다음과 같은 질의문에서 두 번째 피연산자 "CAST (s2 AS STRING COLLATE utf8_tr_cs)"는 서브 표현식이고, 서브 표현식은 칼럼(s1)보다 더 높은 변환도를 가지기 때문에, "CAST (s2 AS STRING COLLATE utf8_tr_cs)"는 s1의 콜레이션으로 변환된다.

.. code-block:: sql

	SELECT s1, s2 FROM t WHERE s1 > CAST (s2 AS STRING COLLATE utf8_tr_cs);

어떤 표현식이든 표현식은 칼럼보다 높은 변환도를 갖는다.

.. code-block:: sql

	SELECT s1, s2 FROM t WHERE s1 > CONCAT (s2,'');

**상수와 칼럼의 콜레이션 변환**

다음의 경우 칼럼 s1의 콜레이션을 사용하여 비교가 수행된다.

.. code-block:: sql

	SELECT s1, s2 FROM t WHERE s1 > 'abc';

**칼럼이 바이너리 콜레이션으로 생성되는 경우**

.. code-block:: sql

	CREATE TABLE t2 (s1 STRING COLLATE utf8_en_cs, s2 STRING COLLATE utf8_bin);

	SELECT s1, s2 FROM t WHERE s1 > s2;

위 경우 s2 칼럼은 바이너리 콜레이션을 가지므로 변환도가 5로 s1 칼럼의 콜레이션으로 "완전히 변환 가능"하며, utf8_en_cs 콜레이션으로 변환된다.

.. code-block:: sql

	CREATE TABLE t2 (s1 STRING COLLATE utf8_en_cs, s2 STRING COLLATE iso88591_bin);

	SELECT s1, s2 FROM t WHERE s1 > s2;

위 경우에도 마찬가지로 콜레이션으로 utf8_en_cs가 사용되는데, s2 칼럼이 ISO 문자셋이므로 UTF-8로 변환하는 오버헤드가 발생한다는 차이가 있다. 실제 문자셋 변환은 ISO를 UTF-8로 변환할 때만 발생한다.

다음 질의문에서, 문자셋 변환은 발생하지 않고(s2에 있는 UTF08의 바이트 데이터는 간단하게 ISO-8859-1 문자셋으로 재해석됨) iso88591_en_cs 콜레이션을 사용하여 문자 비교만 수행된다.

.. code-block:: sql

	CREATE TABLE t2 (s1 STRING COLLATE iso88591_en_cs, s2 STRING COLLATE utf8_bin);

	SELECT s1, s2 FROM t WHERE s1 > s2;

**서브 표현식과 칼럼의 콜레이션 변환**

.. code-block:: sql

	CREATE TABLE t (s1 STRING COLLATE utf8_en_cs, s2 STRING COLLATE utf8_tr_cs);

	SELECT s1, s2 FROM t WHERE s1 > s2 + 'abc';

위 경우 두 번째 피연산자는 표현식이기 때문에 s1의 콜레이션이 사용된다.

다음 예제는 에러가 발생한다. 서로 다른 콜레이션을 지닌 s2와 s3에 대해 '+' 연산을 수행하려고 하기 때문이다.

.. code-block:: sql

	CREATE TABLE t (s1 STRING COLLATE utf8_en_cs, s2 STRING COLLATE utf8_tr_cs, s3 STRING COLLATE utf8_en_ci);

	SELECT s1, s2 FROM t WHERE s1 > s2 + s3;

다음 예제에서는 s2와 s3가 같은 콜레이션이면 '+' 표현식이 utf8_tr_cs이 되고, 비교 연산은 utf8_en_cs 콜레이션을 사용해서 수행된다. s1은 칼럼이고, 표현식보다 낮은 변환도를 갖는다.

.. code-block:: sql

	CREATE TABLE t (s1 STRING COLLATE utf8_en_cs, s2 STRING COLLATE utf8_tr_cs, s3 STRING COLLATE utf8_tr_cs);

	SELECT s1, s2 FROM t WHERE s1 > s2 + s3;

문자셋과 문자열의 콜레이션
--------------------------

문자셋과 문자열(string literal)의 콜레이션은 다음과 같은 우선 순위에 따라 정해진다.

*   **CHARSET** 소개자 또는 문자열의 **COLLATE** 수정자
*   문자셋과 **SET NAMES** 문으로 가장 마지막에 명시한 콜레이션
*   문자셋과 **CUBRID_LANG** 환경 변수에 의해 설정된 기본 콜레이션

**SET NAMES 문**

**SET NAMES** 문은 기본 클라이언트 문자셋과 콜레이션 값을 변경하여, 이를 실행한 클라이언트에서 이후에 실행하는 모든 문장은 지정한 문자셋과 콜레이션을 가지게 된다. 구문은 다음과 같다. ::

	SET NAMES [ charset_name ] [{COLLATION | COLLATE} collation_name]

*   *charset_name* : 유효한 문자셋 이름은 iso88591, utf8 그리고 euckr이다.

*   *collation_name* : 콜레이션 지정은 생략할 수 있으며, 모든 가능한 콜레이션이 설정될 수 있다. 콜레이션과 문자셋은 호환되어야 하며, 그렇지 않으면 오류가 발생한다. 사용 가능한 콜레이션 이름은 **db_collation** 카탈로그 뷰를 검색하여 확인할 수 있다(`칼럼의 콜레이션과 문자셋 <#admin_admin_i18n_collation_colum_3602>`_ 의 `콜레이션 <#admin_admin_i18n_collation_colum_7372>`_ 참고).

**CHARSET 소개자**

상수 문자열 앞에는 **CHARSET** 소개자(introducer)와 **COLLATE** 수정자(modifier)가 올 수 있는데, **CHARSET** 소개자는 언더바(_)로 시작하는 문자셋 이름으로, 상수 문자열 앞에 올 수 있다. 문자열에 대해 **CHARSET** 소개자와 **COLLATE** 수정자를 지정하는 구문은 다음과 같다. ::

	[charset_introducer]'constant-string' [ {COLLATE|COLLATION} collation_name]

*   *charset_introducer* : 언더바(_)를 앞에 붙인 문자셋 이름으로, 생략할 수 있다. _utf8, _iso88591, _euckr 중 하나를 입력할 수 있다.
*   *constant-string* : 상수 문자열 값이다.
*   *collation_name* : 시스템에서 사용 가능한 콜레이션 이름으로, 생략할 수 있다.

상수 문자열의 기본 문자셋과 콜레이션은 현재의 데이터베이스 연결을 기준으로 정해진다(가장 마지막에 수행한 **SET NAMES** 문 혹은 기본값). **CHARSET** 소개자 또는 **COLLATE** 수정자를 생략했을 때는 다음과 같이 동작한다.

*   **CHARSET** 소개자를 지정하고 **COLLATE** 수정자를 생략하면, 해당 문자셋의 기본 콜레이션(바이너리 콜레이션)이 설정된다.
*   **CHARSET** 소개자를 생략하고 **COLLATE** 수정자를 지정하면, 문자셋은 콜레이션에 따라 설정된다.

**예제**

다음은 **SET NAMES** 예제이다.

.. code-block:: sql

	SET NAMES iso88591;
	SET NAMES utf8 COLLATE utf8_en_cs;

다음은 **CHARSET** 소개자와 **COLLATE** 수정자를 지정하는 예제이다. ::

.. code-block:: sql

	SELECT 'cubrid';
	SELECT _utf8'cubrid';
	SELECT _utf8'cubrid' COLLATE utf8_en_cs;

**참고 사항**

**SET NAME** 문 문자셋과 JDBC 문자셋은 서로 같은 문자셋이더라도 표기 방법은 약간의 차이가 있으며, 이들을 비교하면 다음과 같다.

+--------------------+--------------+
| SET NAME 문 문자셋 | JDBC 문자셋  |
+====================+==============+
| iso88591           | ISO-8859-1   |
+--------------------+--------------+
| utf8               | UTF-8        |
+--------------------+--------------+
| euckr              | EUC_KR       |
+--------------------+--------------+

연결 문자열에서 사용되는 JDBC 문자셋의 예를 들면 다음과 같다. ::

	url = "jdbc:cubrid:127.0.0.1:33000:demodb:dba::?charset=UTF-8";

콜레이션의 축약과 확장
----------------------

콜레이션의 구축을 위해 축약(contraction)과 확장(expansion)을 지원하며, 축약과 확장은 UTF-8 문자셋 콜레이션에서만 가능하다. 이러한 축약과 확장은 LDML 파일의 콜레이션 설정에서 나타나는데, 이들의 사용은 로캘 데이터(공유 라이브러리)의 크기와 서버의 성능 모두에 영향을 미친다.

**축약**

축약은 둘 또는 그 이상의 코드포인트로 이루어진 일련의 문자들을 하나의 문자로 간주하여 정렬하는 일련의 시퀀스들로 구성된다. 예를 들어, 전통적인 스페인어 정렬 순서에서 "ch"는 하나의 문자로 간주된다. "ch"로 시작하는 모든 단어들은 "c"로 시작하는 모든 단어들 뒤에 정렬되지만, "d"로 시작하는 단어보다 앞에 위치한다. 축약의 다른 예는 체코어의 "ch"인데 "h" 뒤에 정렬되며, 크로아티아어와 세르비아어의 라틴 문자에서 "lj"와 "nj"는 각각 "l"과 "n" 뒤에 정렬된다. 축약에 대한 추가 정보는 `http://userguide.icu-project.org/collation/concepts <http://userguide.icu-project.org/collation/concepts>`_ 를 참고한다. `http://www.unicode.org/Public/UCA/latest/allkeys.txt <http://www.unicode.org/Public/UCA/latest/allkeys.txt>`_ 의 DUCET에도 축약에 대해 일부가 정의되어 있다.

확장이 있는 콜레이션과 확장이 없는 콜레이션 모두에 대해 축약을 지원하며, 축약은 LDML 파일의 파라미터에 의해 제어된다. 콜레이션을 정의하는 <setting> 태그에서 **DUCETContractions="ignore/use"** 와 **TailoringContractions="ignore/use"** 가 사용된다. DUCETContractions는 DUCET 파일에 있는 축약을 콜레이션에 로딩할 것인지 여부를 제어하고, TailoringContractions는 LDML에 정의된 규칙에 의해 정의된 축약을 사용할 것인지를 제어한다.

**확장**

확장은 하나의 콜레이션 원소보다 많은 원소들을 가진 코드포인트들을 참조한다. 확장을 가능하게 하려면 아래에 서술된 바와 같이 콜레이션의 동작이 근본적으로 변경된다. LDML 파일의 CUBRIDExpansions="use" 파라미터 설정을 통해 확장을 사용할 수 있다.

**확장이 없는 콜레이션**

확장이 없는 콜레이션에서 각 코드포인트는 개별적으로 다루어진다. 콜레이션의 세기에 기반하여 문자들이 완전히 정렬될 수도 있고 그렇지 않을 수도 있다. 콜레이션 알고리즘은 각 수준들의 집합의 가중치를 비교함으로써 코드포인트들을 정렬하며, 그리고 나서 해당 코드포인트의 가중치를 나타내는 하나의 값을 생성한다. 확장이 없는 콜레이션으로 두 문자열을 비교한다는 것은 이와 같이 계산된 가중치를 사용하여 코드포인트를 비교한다는 것을 의미한다.

**확장이 있는 콜레이션**

확장이 있는 콜레이션에서 일부 결합 문자(코드포인트)들은 다른 문자들로 구성된 순서 있는 리스트(ordered list)로 해석된다. 예를 들어, 'æ'는 'ae', 'a'는 ''ae'' 또는 ''aa''와 같이 해석된다. DUCET에서 'æ'의 콜레이션 원소 리스트는 'a'와 'e'의 순서로 두 콜레이션 원소 리스트들을 연결(concatenation)한 것이 된다. 코드포인트에 대해 특정한 순서를 부여하는 것은 불가능하며, 각 문자(코드포인트)들의 새로운 가중치를 계산하는 것도 불가능하다.

확장이 있는 콜레이션에서 문자열 비교는 두 개의 코드포인트/축약에 대해 콜레이션 원소들을 연결(concatenation)한 후에 각 단계별로 두 리스트의 가중치를 비교하는 것이다.

**예제**

다음의 예제는 콜레이션 설정에 따라 문자열 비교가 다른 결과를 가져올 수 있다는 것을 보여준다. 

다음은 DUCET 파일에 존재하는 비교를 위해 사용되는 코드포인트의 라인들이다. ::

	0041  ; [.15A3.0020.0008.0041] # LATIN CAPITAL LETTER A
	0052  ; [.1770.0020.0008.0052] # LATIN CAPITAL LETTER R
	0061  ; [.15A3.0020.0002.0061] # LATIN SMALL LETTER A
	0072  ; [.1770.0020.0002.0072] # LATIN SMALL LETTER R
	00C4  ; [.15A3.0020.0008.0041][.0000.0047.0002.0308] # LATIN CAPITAL LETTER A WITH DIAERESIS;
	00E4  ; [.15A3.0020.0002.0061][.0000.0047.0002.0308] # LATIN SMALL LETTER A WITH DIAERESIS;

이 예제에서는 콜레이션을 위해 세 가지 설정 타입이 표현되어 있다.

*   첫 번째 세기(primary strength), 대소문자 구분 없음(단계 1).
*   두 번째 세기(secondary strength), 대소문자 구분 없음(단계 1, 2)
*   세 번째 세기(tertiary strength), 대문자 우선(단계 1, 2, 3)

지금부터 확장이 있는 콜레이션과 확장이 없는 콜레이션을 가지고 문자열 ''Ar''과 ''Ar''의 정렬을 살펴볼 것이다.

**확장이 없는 콜레이션**

확장이 없을 때 각 코드포인트는 새로운 하나의 값을 가진 가중치를 재할당한다. A, A, A, R과 그들의 소문자에 대한 가중치에 대해 이러한 문자들에 대한 코드포인트의 순서는 위에서 언급한 세 가지 콜레이션 설정 타입을 기준으로 다음과 같다.

*   첫 번째 세기: A = A < R = r
*   두 번째 세기: A < A < R = r
*   세 번째 세기: A < A < R < r

각 코드포인트에 대해 계산된 가중치를 통해 문자열들의 정렬 순서는 쉽게 결정된다.

*   첫 번째 세기: ''Ar'' = ''Ar''
*   두 번째 세기: ''Ar'' < ''Ar''
*   세 번째 세기: ''Ar'' < ''Ar''

**확장이 있는 콜레이션**

확장이 있는 콜레이션이면 정렬 순서가 바뀐다. DUCET에 기반하여 예제에서 문자열에 대한 콜레이션 원소들의 연결된 리스트들은 다음과 같다. ::

	Ar      [.15A3.0020.0008.0041][.1770.0020.0002.0072]
	Är      [.15A3.0020.0008.0041][.0000.0047.0002.0308][.1770.0020.0002.0072]

수준 1의 첫 번째 과정에서 가중치 0x15A3가 0x15A3와 비교된다. 두 번째 과정에서 가중치 0x0000은 비교가 생략되고, 0x1770은 0x1770과 비교된다. 지금까지는 문자열이 동일하므로 수준 2 가중치에 대해 계속 비교하게 되는데, 첫 번째 과정에서 0x0020을 0x0020과 비교하고 두 번째 과정에서 0x0020을 0x0047과 비교하게 되면서 ''Ar'' > ''Ar''이라는 결과를 생성한다. 이 예제를 통해 확장이 있는 콜레이션을 사용할 때 어떻게 문자열 비교가 수행되는지 살펴보았다.

이제 콜레이션 설정을 바꿔서 독일어에 대한 콜레이션을 사용할 때 같은 문자열에 대해 다른 순서를 획득하는 방법을 살펴보자. 독일어에서 ''A''은 문자 그룹 ''AE''로 해석된다. 이 예에 해당하는 코드포인트와 문자들의 콜레이션 원소들은 다음과 같다. ::

	0041  ; [.15A3.0020.0008.0041] # LATIN CAPITAL LETTER A
	0045  ; [.15FF.0020.0008.0045] # LATIN CAPITAL LETTER E
	0072  ; [.1770.0020.0002.0072] # LATIN SMALL LETTER R
	00C4  ; [.15A3.0020.0008.0041][.15FF.0020.0008.0045] # LATIN CAPITAL LETTER A WITH DIAERESIS; EXPANSION

문자열 ''Ar''과 ''Ar''을 비교할 때 확장이 있는 콜레이션을 사용하면, 두 문자열에 있는 문자들의 콜레이션 원소 리스트를 결합한 후 비교하는 과정이 포함된다. ::

	Ar      [.15A3.0020.0008.0041][.1770.0020.0002.0072]
	Är      [.15A3.0020.0008.0041][.15FF.0020.0008.0045][.1770.0020.0002.0072]

첫 번째 과정에서 수준 1의 가중치 0x15A3과 0x15A3를 비교한다. 그리고나서 0x1770과 0x15FF를 비교하여 ''Ar'' < ''Ar''라는 결과가 나오는데, 이는 앞의 예제와는 전혀 다른 결과이다.

콜레이션 관련 특정 연산의 동작
------------------------------

**LIKE 조건 변경 최적화**

**LIKE** 조건 표현식은 문자열 데이터 간 패턴을 비교하고, 검색할 단어가 패턴과 매칭되는 문자열이면 **TRUE** 를 리턴한다. 확장이 없는 콜레이션을 사용할 때에는 각 코드포인트는 가중치를 나타내는 하나의 정수 값을 갖는데, 이 가중치 값은 콜레이션 설정(세기, 대소문자 구분 등)에 기반하여 계산된다.

문자들은 항상 하나의 개체(entity)로 간주될 수 있기 때문에 **LIKE** 조건을 사용한 패턴으로 문자열을 매칭하려는 시도는 문자열이 어떤 범위 내에서 발견될 수 있는지 확인하는 것과 같다고 볼 수 있다. 예를 들어, "s LIKE 'abc%'"와 같은 절을 수행하기 위해 먼저 칼럼 s의 문자열에 대한 제한 범위로 구문을 재작성한다. "s LIKE 'abc%'"는 칼럼 s의 값은 문자열 "abc"로 시작해야 한다는 것을 의미한다. 확장이 없는 콜레이션에서 이는 s가 "abc"보다 크거나 같지만 뒤따르는 문자열보다 작다는 것과 같은 의미이다. 예를 들어, 영어의 알파벳 기준으로 ''abc''에 뒤따르는 문자열은 ''abd''이므로 아래와 같이 변환할 수 있다. ::

	s LIKE 'abc%' → s ≥ 'abc' AND s < 'abd' (if using strictly the English aphabet)

이와 같이 **LIKE** 조건의 패턴은 간단한 비교 조건으로 대체될 수 있는데, 확장이 있는 콜레이션의 경우는 다르게 동작한다. 확장이 있는 콜레이션이 사용되면 더 이상 DUCET 기반의 각 코드포인트에 대해서 가중치 값을 계산하지 않고 가중치 값들에 상응하는 콜레이션 원소 리스트의 정보는 (심지어 압축이 되더라도) 원래 값들로 저장된다. 그런 콜레이션을 사용할 때 문자열을 비교하는 것은 각 코드포인트나 확장에 대해 각 수준(level)별로 콜레이션 원소의 결합된 리스트들을 비교하는 것을 뜻한다. 따라서 확장이 있는 콜레이션에 대해서 위의 예와 같이 **LIKE** 조건을 일반 비교 조건으로 변환하면 비교가 잘못될 수 있다.

정확한 질의 결과를 보장하기 위하여 확장이 있는 콜레이션의 경우에는 **LIKE** 조건 재작성 방법이 아래의 예와 같이 다르게 동작한다. 즉, 범위 조건으로 변경하고 확장 있는 콜레이션에서 잘못 추가될 수 있는 데이터들을 배제시키기 위해 주어진 **LIKE** 조건이 필터로 추가된다. ::

	s LIKE 'abc%' → s ≥ 'abc' AND s < 'abd' and s LIKE 'abc%' (if using strictly the English aphabet)

**prefix 인덱스와 콜레이션 확장**

확장이 없는 콜레이션에서는 prefix 인덱스를 생성할 수 있지만, 확장이 있는 콜레이션을 가진 칼럼에는 prefix 인덱스를 생성할 수 없다.

.. code-block:: sql

	CREATE TABLE t1 (s1 VARCHAR(200) COLLATE utf8_ja_exp);
	CREATE INDEX idx_t_s1 on t(s1(5));   -> not allowed : error

**커버링 인덱스**

커버링 인덱스 스캔은 실제 레코드를 액세스하지 않고 인덱스에 있는 값만을 사용해서 질의를 처리하는 질의 최적화 기법이다.

대소문자 구분이 없는 콜레이션에서 ‘abc’와 ‘ABC’ 두 개의 문자열을 인덱스에 저장한다고 가정할 때 인덱스의 키 값으로 이 중 하나만이 저장된다. 이런 경우에 인덱스 키 값만으로 질의 결과를 만들게 되면 잘못된 결과가 나올 수 있다. 이와 같이 하나의 콜레이션에서 서로 다른 두 개 이상의 스트링이 하나의 키 값을 가지게 되면 정확한 질의 결과를 만들어낼 수 없게 된다. 결국 수준 4(quarternary)보다 작은 가중치 세기의 UTF-8 콜레이션에서 커버링 인덱스에 의한 질의 최적화는 사용할 수 없다. 이러한 세기 값은 LDML에서 콜레이션 정의를 위한 <strength> 태그의 strength=”tertiary/quarternary”에 의해 제어할 수 있는데, 확장이 있는 콜레이션의 세기 값을 최대 값으로 설정하는 것은 주의깊게 고려되어야 한다. 가중치의 네 번째 수준은 공유 라이브러리 크기와 메모리 요구량이 커질 뿐만 아니라 문자열 비교 시간을 증가시키게 된다.

콜레이션과 관련된 자세한 내용은 `다국어 지원 > 콜레이션 설정 <#admin_admin_i18n_collation_intro_1033>`_ 을 참고한다.

인덱스 커버링에 대한 자세한 내용은 `CUBRID SQL 설명서 > 질의 최적화 > 인덱스 활용 > 커버링 인덱스 <#syntax_syntax_retreive_index_cov_7428>`_ 를 참고한다.

주의 사항
=========

*   문자셋은 데이터베이스 인스턴스마다 같다고 가정한다. UTF-8 문자셋으로 구동된 데이터베이스 인스턴스에 JDBC, CCI 드라이버를 통해 응용 프로그램으로부터 직접 UTF-8 문자를 입력하는 것이 가능하다. ISO 문자셋을 사용하는 경우에는 입력되는 모든 문자열이 ISO 문자로 여겨지며 UTF-8 문자셋으로 변환된다. ASCII 문자들은 ISO와 UTF-8 문자셋과 모두 호환되기 때문에 변환되지 않는다.

*   **COLLATE** 수정자는 **ORDER BY**, **GROUP BY**, 콜레이션을 사용하는 연산 등에서 지원되지 않는다. 이 경우 **CAST** 연산자로 문자셋과 콜레이션을 표현식에서 바꿔서 사용할 수 있다.

*   **COLLATE** 수정자를 테이블 단위에서 지정할 수 없고, 컬럼 단위로만 지정할 수 있다. 테이블에서 콜레이션을 설정하면 해당 테이블의 모든 칼럼의 기본 콜레이션으로 지정되는 방법은 지원되지 않는다.

*   콜레이션은 문자열 타입만 지정할 수 있고, **ENUM** 타입에서는 지원되지 않는다.

*   대소문자 구분없는 콜레이션에서 **LIKE** 연산자는 여전히 대소문자를 구분하여 문자열을 처리한다. 다음 버전에서 지원될 예정이다.

*   데이터베이스를 생성하는데 사용된 콜레이션과 다른 콜레이션으로 데이터베이스를 구동해서는 안 된다. 이와 같이 사용하면 예상치 않는 결과를 얻을 수 있고 심지어 CUBRID 프로세스들이 비정상 종료될 수도 있다.

*   호스트 변수의 지연 바인딩이 있는 경우에 질의 실행 계획 출력 시에 콜레이션이 출력되지 않는다.

*   유니코드 코드포인트에서 기본 다국어 영역인 0000~FFFF 범위만 지원한다.

*   하나의 데이터베이스 인스턴스에서 여러 개의 로캘 라이브러리를 동시에 사용할 수 없다.

*   확장이 있는 콜레이션에 대한 문자열 인덱스의 prefix 키 최적화는 현재 지원되지 않고 있고 문자열 전체를 prefix로 사용하는 오버헤드가 있다.

*   "French Order"는 지원되지 않는다. 이는 UCA의 콜레이션 가중치 레벨 2에 대해서 역순 정렬 비교가 필요한데, 현재 지원되지 않는다.

*   Case multiplier가 있는 콜레이션 알파벳(예: de_DE)들에 대한 대소문자 비교가 정확하지 않는 경우가 있다.

*   숫자 구분자로 특정 문자(예를 들어, 공백 문자)를 사용할 수 없다. 일부 로캘에서는 공백 문자를 숫자 구분자로 활용하기도 하는데, 이는 허용되지 않는다.
